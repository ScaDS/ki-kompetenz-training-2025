## Bildgenerierung

* [ChatGPT](https://chat.openai.com/)
* [Gemini]()
* [Stabe Diffusion]()
* , [Claude](https://claude.ai/) oder [Gemini](https://gemini.google.com/app).

### Bias

Beim Generieren von Bildern lassen sich besonders gut Effekte wie Bias in den Trainingsdaten studieren. Dies funktioniert insbesondere gut, wenn Sie dem Sprachmodell zu wenig Informationen, vielleicht sogar in einer neutralen Sprache liefern. Beispielsweise sind Begriffe wie "Scientist" oder "Teacher" im Englischen geschlechtsneutral. Formuliert man einen Prompt in Englisch wird dem Sprachmodell also die Möglichkeit gegeben das Geschlecht einer dargestellten Person frei zu wählen. Diese Wahl trifft es aufgrund der Verteilung von Geschlechtern in Trainingsdaten. 

Generieren Sie mehrere (!) Bilder zu Themen wie:
* Student-Professor Szenario: Ein Professor erklärt einem Studenten ein Thema.
* Ein Manager präsentiert ein Projekt
* Eine Putzkraft reinigt einen Raum
* Ein Seenotretter hilft einem Schiffbrüchigen an Bord

Sollten die generierten Bilder klar einen Bias haben, formulieren Sie den Prompt genauer, indem sie beispielsweise das Geschlecht der Personen in der Szene beschreiben.

### Markenschutz

Erzeugen Sie Bilder, die so beschrieben sind, dass sie möglicherweise Markenschutzrechte verletzten könnten. Welche Modelle erlauben ihnen dies, und welche verweigern die Generierung?

Beispiele
* Eine Lila Kuh auf einer Schokoladenverpackung
* Eine Comic-Ente
* Ein roter Bulle auf weiß-blauen Grund
